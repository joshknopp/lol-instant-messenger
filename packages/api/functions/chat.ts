import { api, secret } from '@nitric/sdk';
import { OpenAI } from 'openai';
import { v4 as uuidv4 } from 'uuid';

const cors = (ctx, next) => {
  const { headers } = ctx.req

  // Allow all Origins
  ctx.res.headers['Access-Control-Allow-Origin'] = ['*','http://localhost:4200']

  // Local dev only (i.e. localhost)
  //ctx.res.headers['Access-Control-Allow-Origin'] = ['http://localhost:4200']
  
  ctx.res.headers['Access-Control-Allow-Methods'] = [
    'GET, POST, PATCH, DELETE, OPTIONS',
  ]

  if (headers['Access-Control-Request-Headers']) {
    ctx.res.headers['Access-Control-Allow-Headers'] = Array.isArray(
      headers['Access-Control-Request-Headers']
    )
      ? headers['Access-Control-Request-Headers']
      : [headers['Access-Control-Request-Headers']]
  }

  return next(ctx)
}

const chatApi = api('main', {
  // add at API level
  middleware: [cors],
});

const apiKeyWritable = secret('api-key').for('put');
const apiKeyReadable = secret('api-key').for('access');

const conversations = new Map<string, any>();

async function getRandomCharacterName(): Promise<string> {
  const characters: string[] = [
    'Austin Powers',
    'The Fresh Prince (Will Smith)',
    'Steve Urkel (Family Matters)',
    'Screech (Saved by the Bell)',
    'Forrest Gump',
    'Fox Mulder (The X-Files)',
    'Tony Stark (Iron Man)',
    'Cher Horowitz (Clueless)',
    'Buffy Summers (Buffy the Vampire Slayer)',
    'Joey Tribbiani (Friends)',
    'Tommy Pickles (Rugrats)',
    'Homer Simpson (The Simpsons)',
    'Scary Spice (Mel B)',
    'Uncle Joey Gladstone (Full House)',
    'Carmen Sandiego',
    'Clarissa Darling (Clarissa Explains It All)',
    'Captain Jack Sparrow (Pirates of the Caribbean)',
    'Miss Piggy (The Muppets)',
    'Wayne and Garth (Wayne\'s World)',
    'Dr. Evil (Austin Powers)'
  ];
  
  return characters[Math.floor(Math.random() * characters.length)];
}

async function getCharacterInstruction(characterName?: string): Promise<string> {
  // TODO This will eventually be generated by OpenAI, and possibly cached in a data store for repeats
  if (!characterName) {
    characterName = await getRandomCharacterName();
  }
  return `You are ${characterName} and the user is chatting with you in an instant messaging application similar to AOL Instant Messenger. ` +
    `Every response must be completely in character, including occasional use of catch phrases. ` +
    `If you are from a specific era in time, only use language and reference events appropriate to your time period. ` +
    `Keep responses brief in order to maintain a back-and-forth conversational cadence. ` +
    `Use shorthand, punctuation, and captalization appropriate to a very informal messaging format, and consider mirroring grammar based on user input. ` +
    `Also note this is AOL Instant Messenger from the 90s, so no emojis are available. ` +
    `However, you may very occasionally use simple glyphs like :) for a smile or :( for a frown. `;
}

async function getApiKey(): Promise<string> {
  const latest = await apiKeyReadable.latest().access();
  return latest.asString();
}

async function getClient(): Promise<OpenAI> {
  const apiKey = await getApiKey();
  return new OpenAI({ apiKey });
}

function generateConversationId(): string {
  return uuidv4();
}

async function sendRequestToOpenAI(conversation): Promise<string> {
  const openai: OpenAI = await getClient();
  const chatCompletion = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",
    messages: conversation,
  });
  return chatCompletion.choices[0].message.content;
}

chatApi.get('/health', async (ctx) => {
  ctx.res.status = 200;
  ctx.res.body = 'ack';
});

chatApi.post('/chat', async (ctx) => {
  const input: Record<string, any> = ctx.req.json();
  const userMessage: string = input.message;
  let conversationId: string = input.conversationId;

  if (!conversationId) {
    conversationId = generateConversationId();
    // Initialize the conversation history with a system message
    conversations.set(conversationId, [{ role: 'system', content: await getCharacterInstruction() }]);
  }

  // TODO Think about how to handle service restarts, since convo only lives in memory - currently fails back to vamilla OpenAI which is no good
  let conversationHistory = conversations.get(conversationId) || [];
  conversationHistory.push({ role: 'user', content: userMessage });

  const openAIResponse = await sendRequestToOpenAI(conversationHistory);

  conversationHistory.push({ role: 'assistant', content: openAIResponse });
  conversations.set(conversationId, conversationHistory);

  ctx.res.status = 200;
  ctx.res.json({ conversationId, message: openAIResponse });
});

chatApi.put('/apikey', async (ctx) => {
  try {
    const queryValue: string[] = ctx.req.query.value;
    const value: string = Array.isArray(queryValue) ? queryValue[0] : queryValue;
    const latestVersion = await apiKeyWritable.put(value);

    ctx.res.status = 200;
    ctx.res.headers['Content-Type'] = ['application/json'];
    ctx.res.body = JSON.stringify({ version: latestVersion.version });

  } catch (error) {
    ctx.res.status = 500;
    ctx.res.headers['Content-Type'] = ['text/plain'];
    ctx.res.body = 'Server error';
  }
  return ctx;
});
